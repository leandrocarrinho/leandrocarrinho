# -*- coding: utf-8 -*-
"""Estudo Data Science

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BGzLZEHnJluYrA9Wnnz44ZFb0M-eGhR0

###importando Blibliotecas
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style("whitegrid")

from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize
from sklearn.model_selection import train_test_split
from sklearn import model_selection, tree, preprocessing, metrics, linear_model
from sklearn.svm import LinearSVC
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier
from sklearn.tree import DecisionTreeClassifier
!pip install catboost
import catboost
from catboost import CatBoostClassifier, Pool, cv

from sklearn.model_selection import GridSearchCV

"""###Carregando Arquivos"""

train = pd.read_csv ('train.csv')
test = pd.read_csv ('test.csv')

"""###Iniciando o código"""

train

train.info ()

train.isnull().sum()

train.describe()

test

test.info()

test.isnull().sum()

test.describe()

passengerId = test['PassengerId']
passengerId

titanic_df = train.append(test, ignore_index= True)

train_index = len(train)
test_index = len(titanic_df) - len(test)

titanic_df

titanic_df.info()

titanic_df.isnull().sum()

titanic_df.head(2)

df = pd.DataFrame()

"""
###Survived
"""

titanic_df['Survived'].nunique()

titanic_df['Survived'].unique()

titanic_df['Survived'].isnull().sum()

titanic_df['Survived'].value_counts()

sns.countplot(data = titanic_df, x = 'Survived')

"""###Criar Função"""

def titanic_func(data, column, count = True):
  print(f'Quantidade de valores unicos: {data[column].nunique()}')
  print(f'\nQuais são os valores unicos: {data[column].unique()}')
  print(f'\nQuantidade de valores nulos: {data[column].isnull().sum()}')
  print(f'\nQuantidade por opção: \n{data[column].value_counts()}')

  if count == True:
    sns.countplot(data = data,x = column, hue = 'Survived')
  else:
    sns.displot(data[column], kde = True)

titanic_func(titanic_df, 'Survived')

"""###Continauação do Código"""

df['Survived'] = titanic_df['Survived']
df

"""###Pclass"""

titanic_func(titanic_df, 'Pclass')

df['Pclass'] = titanic_df['Pclass']
df

titanic_df.head(2)

"""###Sex"""

#dois formatos para converter em numero ajudando na machine larning
#titanic_df['Sex'].map({'female': 1, 'male': 0})
titanic_df['Sex'] = titanic_df['Sex'].replace(['male', 'female'], [0,1])

titanic_func(titanic_df, 'Sex')

df['Sex'] = titanic_df['Sex']
df

"""###Age"""

titanic_func(titanic_df, 'Age', False) #o false é para tirar o grafico da funcao

titanic_df.corr()

titanic_df[titanic_df['Pclass'] == 1]['Age'].mean()

titanic_df[titanic_df['Pclass'] == 2]['Age'].mean()

titanic_df[titanic_df['Pclass'] == 3]['Age'].mean()

for i in sorted(titanic_df['Pclass'].unique()):
  print(f'Pessoas da {i}ª classe tem a média de idade de: {titanic_df[titanic_df["Pclass"] == i]["Age"].mean():.2f}')

"""###tratar valores nulos"""

for i in titanic_df.index:
  if pd.isnull(titanic_df['Age'][i]):
    if titanic_df['Pclass'][i] == 1:
      titanic_df['Age'][i] = round(titanic_df[titanic_df['Pclass'] == 1]['Age'].mean())
    elif titanic_df['Pclass'][i] == 2:
      titanic_df['Age'][i] = round(titanic_df[titanic_df['Pclass'] == 2]['Age'].mean())
    elif titanic_df['Pclass'][i] == 3:
      titanic_df['Age'][i] = round(titanic_df[titanic_df['Pclass'] == 3]['Age'].mean())
  else:
    continue

titanic_df[titanic_df['Pclass'] == 1]['Age'].isnull().sum()

df['Age'] = titanic_df['Age']
df

"""###SibSp"""

titanic_func(titanic_df, 'SibSp')

df['SibSp'] = titanic_df['SibSp']
df

"""###Parch"""

titanic_func(titanic_df, 'Parch')

df['Parch'] = titanic_df['Parch']
df

"""###FamilySize

"""

titanic_df['FamilySize'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1

df['FamilySize'] = titanic_df['FamilySize']
df

"""###Fare"""

titanic_func(titanic_df, 'Fare', False)

titanic_df[titanic_df['Fare'].isnull()]

titanic_df[titanic_df['Pclass'] == 3]['Fare'].mean()

titanic_df['Fare'].fillna(titanic_df[titanic_df['Pclass'] == 3]['Fare'].mean(), inplace = True)

titanic_df.isnull().sum()

df['Fare'] = titanic_df['Fare']
df

"""### Embarked"""

titanic_func(titanic_df, 'Embarked')

titanic_df[titanic_df['Embarked'] == 'S']['Survived'].mean()
#Irá gerar uma espécie de porcentagem

titanic_df[titanic_df['Embarked'] == 'S']['Pclass'].mean()

titanic_df[titanic_df['Embarked'] == 'C']['Survived'].mean()

titanic_df[titanic_df['Embarked'] == 'C']['Pclass'].mean()

titanic_df[titanic_df['Embarked'] == 'Q']['Survived'].mean()

titanic_df[titanic_df['Embarked'] == 'Q']['Pclass'].mean()

titanic_df['Embarked'].fillna('C', inplace = True)

titanic_df.isnull().sum()

df['Embarked'] = titanic_df['Embarked']

df

"""###Name"""

titanic_df['Name']

titanic_df['Title'] = titanic_df['Name'].apply(lambda name: name.split(',')[1].split('.')[0].strip()) #/// é um jeito de fazer 
#[titanic_df['Name'][n].split(',')[1].split('.')[0].strip() for n in titanic_df.index] #segundo jeito de fazer mais simples

titanic_df

titanic_df['Title'].nunique() #calcular quantos dados tem diferentes na mesma coluna

titanic_df['Title'].unique()

titanic_df['Title'].value_counts()

titanic_df['Title'] = [n if n in ['Mr', 'Miss', 'Mrs', 'Master'] else 'Person' for n in titanic_df['Title']]

titanic_df['Title'].value_counts()

df['Title'] = titanic_df['Title']
df

titanic_func(titanic_df, 'Title')

pclass = pd.get_dummies(df['Pclass'], prefix = 'Pclass')
title = pd.get_dummies(df['Title'], prefix = 'Title')
embarked = pd.get_dummies(df['Embarked'], prefix = 'Embarked')

titanic_final = pd.concat([df, pclass, title, embarked], axis = 1)
titanic_final

titanic_final.drop(['Pclass', 'Title', 'Embarked'], axis = 1, inplace = True)

titanic_final

"""###Separando os Df's"""

train = titanic_final[:train_index].copy()
test = titanic_final[test_index:].copy()

"""###Modelos de Machine_Learning"""

train['Survived'] = train['Survived'].astype(int)
train

#criando o treino, no caso, o x vai ser o dataframe completo menos a coluna de sobreviventes e o y vai ser somente os sobreviventes 
x = train.drop('Survived', axis = 1)
y = train['Survived']

x_test = test.drop('Survived', axis = 1)
#video 2 minutos 14:00

"""###Criar Função"""

def func_treino(algoritmo, x_train, y_train, vc):
  modelo = algoritmo.fit(x_train, y_train)
  acuracia = round(modelo.score(x_train, y_train) * 100, 2)

  train_pred = model_selection.cross_val_predict(algoritmo, x_train, y_train, cv = vc, n_jobs = -1)
  acuracia_vc = round(metrics.accuracy_score(y_train, train_pred) * 100, 2)

  return acuracia, acuracia_vc

"""###Random_Forest"""

acc_rf, acc_vc_rf = func_treino(RandomForestClassifier(), x, y, 10)

print(f"Acuracia: {acc_rf}")
print(f"Acuracia Validação Cruzada: {acc_vc_rf}")

"""## Logistic Regression"""

acc_log, acc_vc_log = func_treino(LogisticRegression(), x, y, 10)

print(f"Acuracia: {acc_log}")
print(f"Acuracia Validação Cruzada: {acc_vc_log}")

"""### K-Nearest Neighbours"""

acc_KN, acc_vc_kn = func_treino(KNeighborsClassifier(), x, y, 10)

print(f"Acuracia: {acc_KN}")
print(f"Acuracia Validação Cruzada: {acc_vc_kn}")

"""### Gaussian Naive Bayes"""

acc_nb, acc_vc_nb = func_treino(GaussianNB(), x, y, 10)

print(f"Acuracia: {acc_nb}")
print(f"Acuracia Validação Cruzada: {acc_vc_nb}")

"""### Linear Support Vector Machines (SVC)"""

acc_svc, acc_vc_svc = func_treino(LinearSVC(dual = False), x, y, 10)

print(f"Acuracia: {acc_svc}")
print(f"Acuracia Validação Cruzada: {acc_vc_svc}")



"""## Stachastic Gradient Descent"""

acc_sgd, acc_vc_sgd = func_treino(SGDClassifier(), x, y, 10)

print(f"Acuracia: {acc_sgd}")
print(f"Acuracia Validação Cruzada: {acc_vc_sgd}")

"""## Decision Tree Classifier"""

acc_dtc, acc_vc_dtc = func_treino(DecisionTreeClassifier(), x, y, 10)

print(f"Acuracia: {acc_dtc}")
print(f"Acuracia Validação Cruzada: {acc_vc_dtc}")

"""## Gradient Boost Classifier"""

acc_gbc, acc_vc_gbc = func_treino(GradientBoostingClassifier(), x, y, 10)

print(f"Acuracia: {acc_gbc}")
print(f"Acuracia Validação Cruzada: {acc_vc_gbc}")

params = dict(
   max_depth = [n for n in range(1, 5)],
   min_samples_split = [n for n in range(2, 6)],
   min_samples_leaf = [n for n in range(2, 6)],
   n_estimators = [n for n in range(10, 50, 10)]

)

gbc = GradientBoostingClassifier()

gbc_vc = GridSearchCV(estimator= gbc, param_grid = params, cv = 10)

gbc_vc.fit(x, y)

print(f"Melhor pontuação: {gbc_vc.best_score_:.2f}")
print(f"Melhores parâmetros: {gbc_vc.best_estimator_}")

GradientBoostingClassifier_pred = gbc_vc.predict(x_test)

kaggle = pd.DataFrame({'PassengerId': passengerId, 'Survived': GradientBoostingClassifier_pred})

kaggle.to_csv('Titanic_gradient_boosting_pred.csv', index= False)